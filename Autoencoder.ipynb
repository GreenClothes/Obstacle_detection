{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b0ca3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\pc\\anaconda3\\envs\\notebook\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: Module use of python310.dll conflicts with this version of Python.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:62\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Module use of python310.dll conflicts with this version of Python.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, Conv2DTranspose, Dense, Layer, Reshape, InputLayer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malibi_detect\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutlierVAE\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\site-packages\\tensorflow\\python\\__init__.py:36\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:77\u001b[0m\n\u001b[0;32m     75\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 77\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     78\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     79\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     80\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     81\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     82\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     83\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     84\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\pc\\anaconda3\\envs\\notebook\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 62, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: Module use of python310.dll conflicts with this version of Python.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Layer, Reshape, InputLayer\n",
    "from alibi_detect.od import OutlierVAE\n",
    "from alibi_detect.utils.visualize import plot_instance_score, plot_feature_outlier_image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_list = glob('C:/Users/pc/Desktop/road/512/*.jpg')\n",
    "train_img_list, val_img_list = train_test_split(img_list, test_size=0.1, random_state=2023)\n",
    "\n",
    "def img_to_np(fpaths, resize=True):  \n",
    "    img_array = []\n",
    "    for fname in fpaths:\n",
    "      try:\n",
    "        img = Image.open(fname).convert('RGB')\n",
    "        if(resize): img = img.resize((512, 512))\n",
    "        img_array.append(np.asarray(img))\n",
    "      except:\n",
    "        continue\n",
    "    images = np.array(img_array)\n",
    "    return images\n",
    "\n",
    "x_train = img_to_np(train_img_list)\n",
    "x_train = x_train.astype(np.float32) / 255.\n",
    "\n",
    "x_val = img_to_np(val_img_list)\n",
    "x_val = x_val.astype(np.float32) / 255.\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3579e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check image\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629fcfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2048\n",
    "\n",
    "encoder_net = tf.keras.Sequential([\n",
    "    InputLayer(input_shape=(512, 512, 3)),\n",
    "    Conv2D(512, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "    Conv2D(1024, 4, strides=2, padding='same', activation=tf.nn.relu)\n",
    "])\n",
    "\n",
    "decoder_net = tf.keras.Sequential([\n",
    "    InputLayer(input_shape=(latent_dim,)),\n",
    "    Dense(128 * 128 * 512),\n",
    "    Reshape(target_shape=(128, 128, 512)),\n",
    "    Conv2DTranspose(128, 128, strides=2, padding='same', activation=tf.nn.relu),\n",
    "    Conv2DTranspose(3, 4, strides=2, padding='same', activation='sigmoid')\n",
    "])\n",
    "\n",
    "od = OutlierVAE(\n",
    "    threshold=.0004,\n",
    "    score_type='mse',\n",
    "    encoder_net=encoder_net,\n",
    "    decoder_net=decoder_net,\n",
    "    latent_dim=latent_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.fit(\n",
    "    x_train,\n",
    "    epochs=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee4c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.saving import save_detector\n",
    "\n",
    "save_file_path = 'file path for saving weights'\n",
    "save_detector(od, save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282db8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.saving import load_detector\n",
    "\n",
    "od2 = load_detector(save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 12\n",
    "x = x_train[idx].reshape(1, 128, 128, 3)\n",
    "x_recon = od.vae(x).numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 10))\n",
    "\n",
    "axes[0].imshow(x.squeeze())\n",
    "axes[1].imshow(x_recon.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b634d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_preds = od.predict(\n",
    "    x_val,\n",
    "    outlier_type='instance',\n",
    "    return_feature_score=True,\n",
    "    return_instance_score=True\n",
    ")\n",
    "\n",
    "target = np.zeros(x_val.shape[0],).astype(int)\n",
    "labels = ['normal', 'outlier']\n",
    "plot_instance_score(od_preds, target, labels, od.threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee00b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recon = od.vae(x_val).numpy()\n",
    "\n",
    "plot_feature_outlier_image(\n",
    "    od_preds,\n",
    "    x_val,\n",
    "    X_recon=x_recon,\n",
    "    max_instances=5,\n",
    "    outliers_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_outlier_image(\n",
    "    od_preds,\n",
    "    x_val,\n",
    "    X_recon=x_recon,\n",
    "    max_instances=5,\n",
    "    outliers_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6865b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_list = glob('test image file path')\n",
    "\n",
    "x_test = img_to_np(test_img_list[:10])\n",
    "x_test = x_test.astype(np.float32) / 255.\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a4473",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_preds = od.predict(\n",
    "    x_test,\n",
    "    outlier_type='instance',\n",
    "    return_feature_score=True,\n",
    "    return_instance_score=True\n",
    ")\n",
    "\n",
    "target = np.zeros(x_test.shape[0],).astype(int)\n",
    "labels = ['normal', 'outlier']\n",
    "plot_instance_score(od_preds, target, labels, od.threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da06c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee0341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recon = od.vae(x_test).numpy()\n",
    "\n",
    "plot_feature_outlier_image(\n",
    "    od_preds,\n",
    "    x_test,\n",
    "    X_recon=x_recon,\n",
    "    max_instances=10,\n",
    "    outliers_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recon = od.vae(x_test).numpy()\n",
    "\n",
    "plot_feature_outlier_image(\n",
    "    od_preds,\n",
    "    x_test,\n",
    "    X_recon=x_recon,\n",
    "    max_instances=5,\n",
    "    outliers_only=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
