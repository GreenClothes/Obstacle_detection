{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Layer, Reshape, InputLayer\n",
    "from alibi_detect.od import OutlierVAE\n",
    "from alibi_detect.utils.visualize import plot_instance_score, plot_feature_outlier_image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_img_list = glob('train mage file path')\n",
    "val_img_list = glob('val mage file path')\n",
    "\n",
    "def img_to_np(fpaths, resize=True):  \n",
    "    img_array = []\n",
    "    for fname in fpaths:\n",
    "      try:\n",
    "        img = Image.open(fname).convert('RGB')\n",
    "        if(resize): img = img.resize((512, 512))\n",
    "        img_array.append(np.asarray(img))\n",
    "      except:\n",
    "        continue\n",
    "    images = np.array(img_array)\n",
    "    return images\n",
    "\n",
    "x_train = img_to_np(train_img_list)\n",
    "x_train = x_train.astype(np.float32) / 255.\n",
    "\n",
    "x_val = img_to_np(val_img_list)\n",
    "x_val = x_val.astype(np.float32) / 255.\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3579e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check image\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629fcfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2048\n",
    "\n",
    "encoder_net = tf.keras.Sequential([\n",
    "    InputLayer(input_shape=(512, 512, 3)),\n",
    "    Conv2D(512, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "    Conv2D(1024, 4, strides=2, padding='same', activation=tf.nn.relu)\n",
    "])\n",
    "\n",
    "decoder_net = tf.keras.Sequential([\n",
    "    InputLayer(input_shape=(latent_dim,)),\n",
    "    Dense(128 * 128 * 512),\n",
    "    Reshape(target_shape=(128, 128, 512)),\n",
    "    Conv2DTranspose(128, 128, strides=2, padding='same', activation=tf.nn.relu),\n",
    "    Conv2DTranspose(3, 4, strides=2, padding='same', activation='sigmoid')\n",
    "])\n",
    "\n",
    "od = OutlierVAE(\n",
    "    threshold=.0004,\n",
    "    score_type='mse',\n",
    "    encoder_net=encoder_net,\n",
    "    decoder_net=decoder_net,\n",
    "    latent_dim=latent_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.fit(\n",
    "    x_train,\n",
    "    epochs=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee4c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.saving import save_detector\n",
    "\n",
    "save_file_path = 'file path for saving weights'\n",
    "save_detector(od, save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282db8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.saving import load_detector\n",
    "\n",
    "od2 = load_detector(save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 12\n",
    "x = x_train[idx].reshape(1, 128, 128, 3)\n",
    "x_recon = od.vae(x).numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 10))\n",
    "\n",
    "axes[0].imshow(x.squeeze())\n",
    "axes[1].imshow(x_recon.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b634d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_preds = od.predict(\n",
    "    x_val,\n",
    "    outlier_type='instance',\n",
    "    return_feature_score=True,\n",
    "    return_instance_score=True\n",
    ")\n",
    "\n",
    "target = np.zeros(x_val.shape[0],).astype(int)\n",
    "labels = ['normal', 'outlier']\n",
    "plot_instance_score(od_preds, target, labels, od.threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee00b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recon = od.vae(x_val).numpy()\n",
    "\n",
    "plot_feature_outlier_image(\n",
    "    od_preds,\n",
    "    x_val,\n",
    "    X_recon=x_recon,\n",
    "    max_instances=5,\n",
    "    outliers_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_outlier_image(\n",
    "    od_preds,\n",
    "    x_val,\n",
    "    X_recon=x_recon,\n",
    "    max_instances=5,\n",
    "    outliers_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6865b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_list = glob('test image file path')\n",
    "\n",
    "x_test = img_to_np(test_img_list[:10])\n",
    "x_test = x_test.astype(np.float32) / 255.\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a4473",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_preds = od.predict(\n",
    "    x_test,\n",
    "    outlier_type='instance',\n",
    "    return_feature_score=True,\n",
    "    return_instance_score=True\n",
    ")\n",
    "\n",
    "target = np.zeros(x_test.shape[0],).astype(int)\n",
    "labels = ['normal', 'outlier']\n",
    "plot_instance_score(od_preds, target, labels, od.threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da06c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee0341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recon = od.vae(x_test).numpy()\n",
    "\n",
    "plot_feature_outlier_image(\n",
    "    od_preds,\n",
    "    x_test,\n",
    "    X_recon=x_recon,\n",
    "    max_instances=10,\n",
    "    outliers_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recon = od.vae(x_test).numpy()\n",
    "\n",
    "plot_feature_outlier_image(\n",
    "    od_preds,\n",
    "    x_test,\n",
    "    X_recon=x_recon,\n",
    "    max_instances=5,\n",
    "    outliers_only=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
